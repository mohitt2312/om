Sure, here's a step-by-step guide to set up and run a matrix multiplication in Hadoop, along with the necessary code and commands.
Step 1: Download the Hadoop Jar Files
sh
Copy code
wget https://goo.gl/G4MyHp -O hadoop-common-2.2.0.jar
wget https://goo.gl/KT8yfB -O hadoop-mapreduce-client-core-2.7.1.jar


Step 2: Create the Mapper File (Map.java)
java
Copy code
import org.apache.hadoop.conf.*;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import java.io.IOException;


public class Map extends Mapper<LongWritable, Text, Text, Text> {
    @Override
    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        Configuration conf = context.getConfiguration();
        int m = Integer.parseInt(conf.get("m"));
        int p = Integer.parseInt(conf.get("p"));
        String line = value.toString();
        String[] indicesAndValue = line.split(",");
        Text outputKey = new Text();
        Text outputValue = new Text();


        if (indicesAndValue[0].equals("M")) {
            for (int k = 0; k < p; k++) {
                outputKey.set(indicesAndValue[1] + "," + k);
                outputValue.set(indicesAndValue[0] + "," + indicesAndValue[2] + "," + indicesAndValue[3]);
                context.write(outputKey, outputValue);
            }
        } else {
            for (int i = 0; i < m; i++) {
                outputKey.set(i + "," + indicesAndValue[2]);
                outputValue.set("N," + indicesAndValue[1] + "," + indicesAndValue[3]);
                context.write(outputKey, outputValue);
            }
        }
    }
}


Step 3: Create the Reducer File (Reduce.java)
java
Copy code
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import java.io.IOException;
import java.util.HashMap;


public class Reduce extends Reducer<Text, Text, Text, Text> {
    @Override
    public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {
        String[] value;
        HashMap<Integer, Float> hashA = new HashMap<>();
        HashMap<Integer, Float> hashB = new HashMap<>();


        for (Text val : values) {
            value = val.toString().split(",");
            if (value[0].equals("M")) {
                hashA.put(Integer.parseInt(value[1]), Float.parseFloat(value[2]));
            } else {
                hashB.put(Integer.parseInt(value[1]), Float.parseFloat(value[2]));
            }
        }


        int n = Integer.parseInt(context.getConfiguration().get("n"));
        float result = 0.0f;


        for (int j = 0; j < n; j++) {
            float m_ij = hashA.containsKey(j) ? hashA.get(j) : 0.0f;
            float n_jk = hashB.containsKey(j) ? hashB.get(j) : 0.0f;
            result += m_ij * n_jk;
        }


        context.write(key, new Text(String.valueOf(result)));
    }
}


Step 4: Create the Driver File (MatrixMultiply.java)
java
Copy code
import org.apache.hadoop.conf.*;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;


public class MatrixMultiply {
    public static void main(String[] args) throws Exception {
        if (args.length != 2) {
            System.err.println("Usage: MatrixMultiply <in_dir> <out_dir>");
            System.exit(2);
        }


        Configuration conf = new Configuration();
        conf.set("m", "1000");
        conf.set("n", "100");
        conf.set("p", "1000");


        Job job = Job.getInstance(conf, "MatrixMultiply");
        job.setJarByClass(MatrixMultiply.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);
        job.setMapperClass(Map.class);
        job.setReducerClass(Reduce.class);
        job.setInputFormatClass(TextInputFormat.class);
        job.setOutputFormatClass(TextOutputFormat.class);


        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));


        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}


Step 5: Compile the Program
sh
Copy code
mkdir -p operation
javac -cp hadoop-common-2.2.0.jar:hadoop-mapreduce-client-core-2.7.1.jar:operation/:. -d operation/ Map.java
javac -cp hadoop-common-2.2.0.jar:hadoop-mapreduce-client-core-2.7.1.jar:operation/:. -d operation/ Reduce.java
javac -cp hadoop-common-2.2.0.jar:hadoop-mapreduce-client-core-2.7.1.jar:operation/:. -d operation/ MatrixMultiply.java


Step 6: Retrieve the Directory After Compilation
sh
Copy code
ls -R operation/


Step 7: Create Jar File for Matrix Multiplication
sh
Copy code
jar -cvf MatrixMultiply.jar -C operation/ .


Step 8: Upload the Matrix Data Files to HDFS
sh
Copy code
echo -e "M,0,0,1\nM,0,1,2\nM,1,0,3\nM,1,1,4" > M
echo -e "N,0,0,5\nN,0,1,6\nN,1,0,7\nN,1,1,8" > N
hadoop fs -mkdir Matrix/
hadoop fs -copyFromLocal M Matrix/
hadoop fs -copyFromLocal N Matrix/


Step 9: Run the Hadoop Job and Get the Output
sh
Copy code
hadoop jar MatrixMultiply.jar MatrixMultiply Matrix/ result/
hadoop fs -cat result/part-r-00000


Sample Output
Copy code
0,0,19.0
0,1,22.0
1,0,43.0
1,1,50.0


Make sure you have Hadoop set up and running, and the HDFS is properly configured to execute these commands successfully.